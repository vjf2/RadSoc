#Calculate home range overlap for all sequenced subjects
#Add ages and sexes

options(stringsAsFactors = FALSE)

library(SocGen)
library(adehabitatHR)
library(rgeos)
library(rgdal)
library(raster)

setwd("C:/Users/froug/Desktop/Real First Chapter")

#load in locations

all_sightings<-read.csv("RawData/all_sightings_with_locations_final.csv")
#generated by get_points_surveys_focals in general home range analysis

all_surveys<-read.csv("RawData/all_surveys_social.csv", row.names = 1)
#generated by social_atributes in Chapter 3

all_surveys$observation_date.x<-as.Date(all_surveys$observation_date.x, format="%Y-%m-%d")

life_history<-read.delim("RawData/LifeHistory20180717.txt", header=TRUE, sep="\t", na.strings = "")

#need to convert date classes

lhl<-life_history[!duplicated(life_history$dolphin_id),]

lhl$birth_date<-as.Date(lhl$birth_date, format="%Y-%m-%d")
lhl$death_date<-as.Date(lhl$death_date, format="%Y-%m-%d")
lhl$weaning_date<-as.Date(lhl$weaning_date, format="%Y-%m-%d")

all_sightings$observation_date<-as.Date(all_sightings$observation_date, format="%m/%d/%Y")

all_sightings$sex<-lhl$sex[match(all_sightings$dolphin_id, lhl$dolphin_id)]

#load in ID_key

ID_key<-read.csv("RawData/dolphin_sample_key.csv")
dolphins<-ID_key$Dolphin_ID[which(ID_key$me_paper %in% c("yes", "yes_v2")
                       & ID_key$Npoints >=35)]
n<-length(dolphins)

all_surveys<-all_surveys[which(all_surveys$dolphin_id %in% dolphins
                               & all_surveys$life_stage=="postweaning"),]


all_sightings<-all_sightings[which(all_sightings$dolphin_id %in% dolphins
                                   & all_sightings$life_stage=="postweaning"),]


##need to intersect all_surveys with all_sightings to get data for null model

gps_info<-all_sightings[!duplicated(all_sightings[,c("source_id", "latitude", "longitude")]),c("source_id", "latitude", "longitude")]

all_surveys<-merge(all_surveys, gps_info,
                   by.x="observation_id", by.y="source_id", all.x=FALSE, all.y=FALSE)

fast_avail<-data.frame(dolphin_id=dolphins, entry=rep(NA, length(dolphins)), depart=rep(NA, length(dolphins)))

fast_avail$entry<-as.Date(lhl$birth_date[match(fast_avail$dolphin_id, lhl$dolphin_id)])#this does not work

#Entry is either weaning date or age 4

fast_avail$weaning<-as.Date(lhl$weaning_date[match(fast_avail$dolphin_id, lhl$dolphin_id)])

fast_avail$entry<-ifelse(is.na(fast_avail$weaning), 
                         fast_avail$entry+(4*365.25),
                         fast_avail$weaning)

fast_avail$entry<-as.Date(fast_avail$entry, origin="1970-01-01")

fast_avail$death<-as.Date(lhl$death_date[match(fast_avail$dolphin_id, lhl$dolphin_id)])

#If no death date add date of last sighting

lsd_dol<-split(all_surveys, as.factor(all_surveys$dolphin_id))

silent<-lapply(lsd_dol, function(x) {fast_avail$depart[match(x$dolphin_id[1], fast_avail$dolphin_id)]<<-as.character(max(x$observation_date.x))})

fast_avail$death<-as.character(fast_avail$death)

fast_avail$depart<-ifelse(is.na(fast_avail$death), fast_avail$depart, fast_avail$death)

fast_avail$depart<-as.Date(fast_avail$depart, format="%Y-%m-%d")

#if no death then add 6 months to depart

fast_avail$depart<-ifelse(is.na(fast_avail$death), 
                          fast_avail$depart+(6*30.5),
                          fast_avail$depart)

fast_avail$depart<-as.Date(fast_avail$depart, origin="1970-01-01")

fast_avail<-fast_avail[,c(1:3)]

#get home range overlap

xydata<-cbind(all_sightings$longitude,all_sightings$latitude)
xydata2<-as.data.frame(project(xydata, "+proj=tmerc +lat_0=-25 +lon_0=113 +k=0.99999 +x_0=50000 +y_0=100000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"))
xydata3<-cbind(all_sightings[,c("observation_date", "source_id", "dolphin_id")],trunc(xydata2,0))
colnames(xydata3)<-c("Date", "observation_id", "dolphin_id","X","Y")

#create a grid on which to model animal home ranges
grid_buffer=5000

x <- seq(min(xydata3[,"X"])-grid_buffer,max(xydata3[,"X"])+grid_buffer,by=100) # where resolution is the pixel size you desire. 100 is the smallest i would go, if you make it larger you'll get coarser resolution, but faster runtimes
y <- seq(min(xydata3[,"Y"])-grid_buffer,max(xydata3[,"Y"])+grid_buffer,by=100)

xy <- expand.grid(x=x,y=y)
coordinates(xy) <- ~x+y
gridded(xy) <- TRUE

#create UDs for each animal and extract the href smoothing parameter (need to manually select h for boundary method)

hrxydata<-SpatialPointsDataFrame(xydata3[,c("X","Y")],xydata3["dolphin_id"])

uds_href<-kernelUD(hrxydata[,1],grid=xy)

#create simplified coastline for the boundary, length of segments must be greater than 3*h
bound <- structure(list(x = c(122000,122000,116500,110000,108000), y = c(1000,10500,14500,20800,29800)), .Names = c("x", "y"))
bound <- do.call("cbind",bound)
Slo1 <- Line(bound)
Sli1 <- Lines(list(Slo1), ID="frontier1")
barrier <- SpatialLines(list(Sli1))

#if any smoothing parameters are too large for the boundary, set them to max allowed
maxh<-trunc(min(dist(bound))/3,0)

#pull out a list of individual smoothing parameters

hvalues<-list()
for (i in 1:length(uds_href)) {
  h<-uds_href[[i]]@h$h
  h<-ifelse(h>maxh,maxh,h)
  id<-names(uds_href)[[i]]
  hvalues[[i]]<-c(h, id)
}

h<-as.data.frame(do.call("rbind", hvalues), stringsAsFactors=FALSE)

names(h)<-c("h_opt", "dolphin_id")

h$h_opt<-as.numeric(h$h_opt)

#remove uds_href and do a memory clean-up

rm("uds_href");gc()

#recalculate the UDs with the boundary this time
optud<-list()

for (i in 1:dim(h)[1]){
  
  cdol<-hrxydata[hrxydata$dolphin_id==h$dolphin_id[i],]
  hopt<-h$h_opt[i]
  uds_man<-kernelUD(cdol,h=hopt,grid=xy, boundary=barrier)
  optud[[i]]<-uds_man
  cat(i)
}

uddf<-unlist(optud)
class(uddf)<-"estUDm"

#read in a polygon on shark bay to do a fine scale trimming of the UDs
coast_polygon<-readOGR("RawData/coastpolygon", "coastpolygon")

coast_polygon<-spTransform(coast_polygon, CRS("+proj=tmerc +lat_0=-25 +lon_0=113 +k=0.99999 +x_0=50000 +y_0=100000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"))

udsgdf <- as(estUDm2spixdf(uddf),"SpatialGridDataFrame")

#use coast polygon as mask for spatial grid

rgrid <- raster(udsgdf)
#plot(rgrid)
rgrid_msk <- mask(rgrid,coast_polygon, inverse=TRUE)

grid_ae <- as(rgrid_msk, 'SpatialGridDataFrame')
gridded(grid_ae) <- TRUE
grid_ae[[1]] <- as.numeric(!is.na(grid_ae[[1]])) 

#multiply each column of udsgdf by the mask, and restandardize the percentages so that each set of probabilities sums to 1

resu <- lapply(1:ncol(udsgdf), function(i) {udsgdf[[i]] * grid_ae[[1]] / sum(udsgdf[[i]] * grid_ae[[1]]) })

resu <- as.data.frame(resu) 
names(resu) <- names(udsgdf@data) 

# and define it as data slot for udsgdf 
udsgdf@data <- resu 

#turn back into estUDm
masked_grid<-udsgdf

fullgrid(masked_grid) <- FALSE 
re <- lapply(1:ncol(masked_grid), function(i) { 
  so <- new("estUD", masked_grid[,i]) 
  so@h <- list(h=0, meth="specified") # fake value 
  so@vol <- FALSE  
  return(so) 
}) 
names(re) <- names(masked_grid) 
class(re) <- "estUDm" 

#calculate HRO per pair

HRO<-kerneloverlaphr(re, method = c("VI"), percent = 95)
HRO<-HRO/10000

VI<-mat2dat(HRO, "HRO")
VI<-reduce_pairs(VI, "ID1", "ID2")

#SRI

dates<-sort(unique(all_surveys$observation_date.x))

alive<-Vectorize(FUN=function(r,c) 
  isTRUE(r>=fast_avail$entry[which(fast_avail$dolphin_id==c)] 
         & r<=fast_avail$depart[which(fast_avail$dolphin_id==c)]))

schedule<-outer(as.numeric(dates), dolphins, FUN=alive) #takes 2 min to run
matnames<-list(as.character(dates),dolphins)
dimnames(schedule)<-matnames

schedule<-t(schedule*1)
schedule[schedule==0]<-NA

masked_SRI<-simple_ratio(sightings=all_surveys, group_variable = "observation_id", 
                         dates="observation_date.x", IDs = "dolphin_id", 
                         symmetric = FALSE,
                         mask = schedule)

SRI<-mat2dat(masked_SRI, "SRI")

#Also need joint number of sightings for weight

attributes<-merge_pairs(VI, SRI, "ID1", "ID2", all.x=TRUE, all.y=FALSE)

#get joint number of sightings with new function

masked_sightings<-simple_ratio(sightings=all_surveys, group_variable = "observation_id", 
                         dates="observation_date.x", IDs = "dolphin_id", 
                         symmetric = FALSE,
                         mask = schedule, 
                         assocInd = "XY")

sightings<-mat2dat(masked_sightings, "sightings")


attributes<-merge_pairs(sightings, attributes, "ID1", "ID2", all.x=TRUE, all.y=FALSE)

#add sex and age information

attributes$by1<-lhl$birth_date[match(attributes$ID1, lhl$dolphin_id)]
attributes$by2<-lhl$birth_date[match(attributes$ID2, lhl$dolphin_id)]

attributes$sex1<-lhl$sex[match(attributes$ID1, lhl$dolphin_id)]
attributes$sex2<-lhl$sex[match(attributes$ID2, lhl$dolphin_id)]

attributes$agediff<-as.numeric(abs(attributes$by1-attributes$by2)/365.25)
attributes$sexpair<-paste0(attributes$sex1, attributes$sex2)
attributes$sexpair[which(attributes$sexpair=="MALEFEMALE")]<-"FEMALEMALE"

write.csv(attributes, file="social_model_variabes.csv")




